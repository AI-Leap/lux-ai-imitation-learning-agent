{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "IMI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KtvEABpKHdZ0",
        "outputId": "7758c2ab-c0b8-411c-e498-34f3802e4140"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTXqIndyHnf6"
      },
      "source": [
        "!tar -xf /content/drive/MyDrive/lux_ai/archive.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_3DEK6jTnjr",
        "outputId": "0943b5fd-b027-49d8-a0fa-ff82f2045841"
      },
      "source": [
        "import numpy as np\n",
        "import json\n",
        "from pathlib import Path\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def seed_everything(seed_value):\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed = 42\n",
        "seed_everything(seed)\n",
        "\n",
        "\n",
        "def to_label(action):\n",
        "    strs = action.split(' ')\n",
        "    unit_id = strs[1]\n",
        "    if strs[0] == 'm':\n",
        "        label = {'c': None, 'n': 0, 's': 1, 'w': 2, 'e': 3}[strs[2]]\n",
        "    elif strs[0] == 'bcity':\n",
        "        label = 4\n",
        "    else:\n",
        "        label = None\n",
        "    return unit_id, label\n",
        "\n",
        "\n",
        "def depleted_resources(obs):\n",
        "    for u in obs['updates']:\n",
        "        if u.split(' ')[0] == 'r':\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def create_dataset_from_json(episode_dir, team_name='Toad Brigade'): \n",
        "    obses = {}\n",
        "    samples = []\n",
        "    append = samples.append\n",
        "    \n",
        "    \n",
        "    episodes = [path for path in Path(episode_dir).glob('*.json') if 'output' not in path.name]\n",
        "    for filepath in episodes: \n",
        "        try:\n",
        "          with open(filepath) as f:\n",
        "              json_load = json.load(f)\n",
        "        except:\n",
        "          continue\n",
        "          \n",
        "        ep_id = json_load['info']['EpisodeId']\n",
        "        index = np.argmax([r or 0 for r in json_load['rewards']])\n",
        "        if json_load['info']['TeamNames'][index] != team_name:\n",
        "            continue\n",
        "\n",
        "        for i in range(len(json_load['steps'])-1):\n",
        "            if json_load['steps'][i][index]['status'] == 'ACTIVE':\n",
        "                actions = json_load['steps'][i+1][index]['action']\n",
        "                obs = json_load['steps'][i][0]['observation']\n",
        "                \n",
        "                if depleted_resources(obs):\n",
        "                    break\n",
        "                \n",
        "                obs['player'] = index\n",
        "                obs = dict([\n",
        "                    (k,v) for k,v in obs.items() \n",
        "                    if k in ['step', 'updates', 'player', 'width', 'height']\n",
        "                ])\n",
        "                obs_id = f'{ep_id}_{i}'\n",
        "                obses[obs_id] = obs\n",
        "                                \n",
        "                for action in actions:\n",
        "                    unit_id, label = to_label(action)\n",
        "                    if label is not None:\n",
        "                        append((obs_id, unit_id, label))\n",
        "\n",
        "    return obses, samples\n",
        "\n",
        "\n",
        "episode_dir = './archive/'\n",
        "obses, samples = create_dataset_from_json(episode_dir)\n",
        "print('obses:', len(obses), 'samples:', len(samples))\n",
        "\n",
        "labels = [sample[-1] for sample in samples]\n",
        "actions = ['north', 'south', 'west', 'east', 'bcity']\n",
        "for value, count in zip(*np.unique(labels, return_counts=True)):\n",
        "    print(f'{actions[value]:^5}: {count:>3}')\n",
        "\n",
        "\n",
        "# Input for Neural Network\n",
        "def make_input(obs, unit_id):\n",
        "    width, height = obs['width'], obs['height']\n",
        "    x_shift = (32 - width) // 2\n",
        "    y_shift = (32 - height) // 2\n",
        "    cities = {}\n",
        "    \n",
        "    b = np.zeros((20, 32, 32), dtype=np.float32)\n",
        "    \n",
        "    for update in obs['updates']:\n",
        "        strs = update.split(' ')\n",
        "        input_identifier = strs[0]\n",
        "        \n",
        "        if input_identifier == 'u':\n",
        "            x = int(strs[4]) + x_shift\n",
        "            y = int(strs[5]) + y_shift\n",
        "            wood = int(strs[7])\n",
        "            coal = int(strs[8])\n",
        "            uranium = int(strs[9])\n",
        "            if unit_id == strs[3]:\n",
        "                # Position and Cargo\n",
        "                b[:2, x, y] = (\n",
        "                    1,\n",
        "                    (wood + coal + uranium) / 100\n",
        "                )\n",
        "            else:\n",
        "                # Units\n",
        "                team = int(strs[2])\n",
        "                cooldown = float(strs[6])\n",
        "                idx = 2 + (team - obs['player']) % 2 * 3\n",
        "                b[idx:idx + 3, x, y] = (\n",
        "                    1,\n",
        "                    cooldown / 6,\n",
        "                    (wood + coal + uranium) / 100\n",
        "                )\n",
        "        elif input_identifier == 'ct':\n",
        "            # CityTiles\n",
        "            team = int(strs[1])\n",
        "            city_id = strs[2]\n",
        "            x = int(strs[3]) + x_shift\n",
        "            y = int(strs[4]) + y_shift\n",
        "            idx = 8 + (team - obs['player']) % 2 * 2\n",
        "            b[idx:idx + 2, x, y] = (\n",
        "                1,\n",
        "                cities[city_id]\n",
        "            )\n",
        "        elif input_identifier == 'r':\n",
        "            # Resources\n",
        "            r_type = strs[1]\n",
        "            x = int(strs[2]) + x_shift\n",
        "            y = int(strs[3]) + y_shift\n",
        "            amt = int(float(strs[4]))\n",
        "            b[{'wood': 12, 'coal': 13, 'uranium': 14}[r_type], x, y] = amt / 800\n",
        "        elif input_identifier == 'rp':\n",
        "            # Research Points\n",
        "            team = int(strs[1])\n",
        "            rp = int(strs[2])\n",
        "            b[15 + (team - obs['player']) % 2, :] = min(rp, 200) / 200\n",
        "        elif input_identifier == 'c':\n",
        "            # Cities\n",
        "            city_id = strs[2]\n",
        "            fuel = float(strs[3])\n",
        "            lightupkeep = float(strs[4])\n",
        "            cities[city_id] = min(fuel / lightupkeep, 10) / 10\n",
        "    \n",
        "    # Day/Night Cycle\n",
        "    b[17, :] = obs['step'] % 40 / 40\n",
        "    # Turns\n",
        "    b[18, :] = obs['step'] / 360\n",
        "    # Map Size\n",
        "    b[19, x_shift:32 - x_shift, y_shift:32 - y_shift] = 1\n",
        "\n",
        "    return b\n",
        "\n",
        "\n",
        "class LuxDataset(Dataset):\n",
        "    def __init__(self, obses, samples):\n",
        "        self.obses = obses\n",
        "        self.samples = samples\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        obs_id, unit_id, action = self.samples[idx]\n",
        "        obs = self.obses[obs_id]\n",
        "        state = make_input(obs, unit_id)\n",
        "        \n",
        "        return state, action\n",
        "\n",
        "\n",
        "# Neural Network for Lux AI\n",
        "class BasicConv2d(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, kernel_size, bn):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(\n",
        "            input_dim, output_dim, \n",
        "            kernel_size=kernel_size, \n",
        "            padding=(kernel_size[0] // 2, kernel_size[1] // 2)\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n",
        "        # self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.conv(x)\n",
        "        h = self.bn(h) if self.bn is not None else h\n",
        "        # h = self.relu(h)\n",
        "        return h\n",
        "\n",
        "\n",
        "class LuxNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        layers, filters = 16, 32\n",
        "        self.conv0 = BasicConv2d(20, filters, (5, 5), True)\n",
        "        self.blocks = nn.ModuleList([BasicConv2d(filters, filters, (5, 5), True) for _ in range(layers)])\n",
        "        self.head_p = nn.Linear(filters, 5, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = F.relu_(self.conv0(x))\n",
        "        for block in self.blocks:\n",
        "            h = F.relu_(h + block(h))\n",
        "        h_head = (h * x[:,:1]).view(h.size(0), h.size(1), -1).sum(-1)\n",
        "        p = self.head_p(h_head)\n",
        "        return p\n",
        "\n",
        "\n",
        "def train_model(model, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "    best_acc = 0.0\n",
        "\n",
        "    step = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.cuda()\n",
        "        \n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "                \n",
        "            epoch_loss = 0.0\n",
        "            epoch_acc = 0\n",
        "            \n",
        "            dataloader = dataloaders_dict[phase]\n",
        "            for item in dataloader:\n",
        "                step += 1\n",
        "                states = item[0].cuda().float()\n",
        "                actions = item[1].cuda().long()\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    policy = model(states)\n",
        "                    loss = criterion(policy, actions)\n",
        "                    _, preds = torch.max(policy, 1)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    epoch_loss += loss.item() * len(policy)\n",
        "                    epoch_acc += torch.sum(preds == actions.data)\n",
        " \n",
        "                    if step % 1000 == 0:\n",
        "                        print(f'{phase} step {step}/{len(dataloader)} loss {loss.item()} acc {epoch_acc / len(dataloader.dataset)}')\n",
        "\n",
        "            data_size = len(dataloader.dataset)\n",
        "            epoch_loss = epoch_loss / data_size\n",
        "            epoch_acc = epoch_acc.double() / data_size\n",
        "\n",
        "            print(f'Epoch {epoch + 1}/{num_epochs} | {phase:^5} | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}')\n",
        "        \n",
        "        if epoch_acc > best_acc:\n",
        "            traced = torch.jit.trace(model.cpu(), torch.rand(1, 20, 32, 32))\n",
        "            traced.save('/content/drive/MyDrive/lux_ai/models/best_model.pth')\n",
        "            best_acc = epoch_acc\n",
        "        traced.save(f'/content/drive/MyDrive/lux_ai/models/epoch_{epoch + 1}_model.pth')\n",
        "\n",
        "\n",
        "model = torch.jit.load(f'{path}/model.pth')\n",
        "train, val = train_test_split(samples, test_size=0.02, random_state=42, stratify=labels)\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(\n",
        "    LuxDataset(obses, train), \n",
        "    batch_size=batch_size, \n",
        "    shuffle=True, \n",
        "    num_workers=1\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    LuxDataset(obses, val), \n",
        "    batch_size=batch_size, \n",
        "    shuffle=False, \n",
        "    num_workers=1\n",
        ")\n",
        "dataloaders_dict = {\"train\": train_loader, \"val\": val_loader}\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "\n",
        "\n",
        "train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "obses: 316577 samples: 1990056\n",
            "north: 500218\n",
            "south: 493006\n",
            "west : 434948\n",
            "east : 436689\n",
            "bcity: 125195\n",
            "train step 1000/30473 loss 1.087083339691162 acc 0.015363640151917934\n",
            "train step 2000/30473 loss 1.1826101541519165 acc 0.034486789256334305\n",
            "train step 3000/30473 loss 0.9227783679962158 acc 0.054565202444791794\n",
            "train step 4000/30473 loss 1.0729199647903442 acc 0.07516200840473175\n",
            "train step 5000/30473 loss 0.7002792954444885 acc 0.09614440053701401\n",
            "train step 6000/30473 loss 0.809474766254425 acc 0.11758416891098022\n",
            "train step 7000/30473 loss 0.5916699767112732 acc 0.1392536610364914\n",
            "train step 8000/30473 loss 0.7215664982795715 acc 0.1611143946647644\n",
            "train step 9000/30473 loss 0.8571895360946655 acc 0.18327203392982483\n",
            "train step 10000/30473 loss 0.8626986742019653 acc 0.2055424600839615\n",
            "train step 11000/30473 loss 0.8496381044387817 acc 0.22804106771945953\n",
            "train step 12000/30473 loss 0.8571694493293762 acc 0.2507058084011078\n",
            "train step 13000/30473 loss 0.6353191137313843 acc 0.2736033499240875\n",
            "train step 14000/30473 loss 0.8947076201438904 acc 0.29632192850112915\n",
            "train step 15000/30473 loss 0.6514093279838562 acc 0.3191753625869751\n",
            "train step 16000/30473 loss 0.5848660469055176 acc 0.3422723412513733\n",
            "train step 17000/30473 loss 0.5888159871101379 acc 0.365233451128006\n",
            "train step 18000/30473 loss 0.8618321418762207 acc 0.3883596658706665\n",
            "train step 19000/30473 loss 0.8024526238441467 acc 0.41158586740493774\n",
            "train step 20000/30473 loss 0.6699363589286804 acc 0.43492797017097473\n",
            "train step 21000/30473 loss 0.8629723787307739 acc 0.4582654535770416\n",
            "train step 22000/30473 loss 0.7199810147285461 acc 0.4816265106201172\n",
            "train step 23000/30473 loss 0.6222603917121887 acc 0.5050798654556274\n",
            "train step 24000/30473 loss 0.516118049621582 acc 0.5287178158760071\n",
            "train step 25000/30473 loss 0.7115750908851624 acc 0.5522403717041016\n",
            "train step 26000/30473 loss 0.5969471335411072 acc 0.5758393406867981\n",
            "train step 27000/30473 loss 0.7387495636940002 acc 0.599433183670044\n",
            "train step 28000/30473 loss 0.5984296202659607 acc 0.6230250000953674\n",
            "train step 29000/30473 loss 0.7445946335792542 acc 0.6466306447982788\n",
            "train step 30000/30473 loss 0.968364953994751 acc 0.6702465415000916\n",
            "Epoch 1/20 | train | Loss: 0.7771 | Acc: 0.6815\n",
            "val step 31000/622 loss 0.7806450128555298 acc 0.6132103800773621\n",
            "Epoch 1/20 |  val  | Loss: 0.6742 | Acc: 0.7242\n",
            "train step 32000/30473 loss 0.810989260673523 acc 0.021628977730870247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E33JpKtONace"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}